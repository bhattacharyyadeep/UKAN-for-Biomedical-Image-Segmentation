{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nVATtKeQVp9",
        "outputId": "bd1888f9-5f85-4928-de54-e06be4cc4082"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahP0c3LGVHYH"
      },
      "outputs": [],
      "source": [
        "image_dir = '/content/drive/MyDrive/Seg_UKAN/inputs/busi/busi/images'\n",
        "mask_dir = '/content/drive/MyDrive/Seg_UKAN/inputs/busi/busi/masks/0'\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, jaccard_score"
      ],
      "metadata": {
        "id": "kOYIE07cmF5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_HQBAjCWwxA"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        # Contracting path\n",
        "        self.enc1 = self.conv_block(3, 64)\n",
        "        self.enc2 = self.conv_block(64, 128)\n",
        "        self.enc3 = self.conv_block(128, 256)\n",
        "        self.enc4 = self.conv_block(256, 512)\n",
        "        self.enc5 = self.conv_block(512, 1024)\n",
        "\n",
        "        # Expansive path\n",
        "        self.up6 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.dec6 = self.conv_block(1024, 512)  # Adjust concatenated input size\n",
        "\n",
        "        self.up7 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.dec7 = self.conv_block(512, 256)  # Adjust concatenated input size\n",
        "\n",
        "        self.up8 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.dec8 = self.conv_block(256, 128)  # Adjust concatenated input size\n",
        "\n",
        "        self.up9 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.dec9 = self.conv_block(128, 64)   # Adjust concatenated input size\n",
        "\n",
        "        self.final = nn.Conv2d(64, 1, kernel_size=1)  # Final output to binary mask\n",
        "\n",
        "    def conv_block(self, in_channels, out_channels):\n",
        "        block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        return block\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Contracting path\n",
        "        enc1 = self.enc1(x)\n",
        "        enc2 = self.enc2(nn.functional.max_pool2d(enc1, 2))\n",
        "        enc3 = self.enc3(nn.functional.max_pool2d(enc2, 2))\n",
        "        enc4 = self.enc4(nn.functional.max_pool2d(enc3, 2))\n",
        "        enc5 = self.enc5(nn.functional.max_pool2d(enc4, 2))\n",
        "\n",
        "        # Expansive path\n",
        "        up6 = self.up6(enc5)\n",
        "        dec6 = self.dec6(torch.cat([up6, enc4], dim=1))\n",
        "\n",
        "        up7 = self.up7(dec6)\n",
        "        dec7 = self.dec7(torch.cat([up7, enc3], dim=1))\n",
        "\n",
        "        up8 = self.up8(dec7)\n",
        "        dec8 = self.dec8(torch.cat([up8, enc2], dim=1))\n",
        "\n",
        "        up9 = self.up9(dec8)\n",
        "        dec9 = self.dec9(torch.cat([up9, enc1], dim=1))\n",
        "\n",
        "        # Final layer\n",
        "        output = torch.sigmoid(self.final(dec9))\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iABXtZnaW0iD"
      },
      "outputs": [],
      "source": [
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, img_size=(128, 128), transform=None):\n",
        "        self.image_files = sorted(os.listdir(image_dir))\n",
        "        self.mask_files = sorted(os.listdir(mask_dir))\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.img_size = img_size\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.image_files[idx])\n",
        "        mask_path = os.path.join(self.mask_dir, self.mask_files[idx])\n",
        "\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "        img = cv2.resize(img, self.img_size)\n",
        "        img = img.astype(np.float32)  / 255.0\n",
        "\n",
        "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
        "        mask = cv2.resize(mask, self.img_size)\n",
        "        mask = mask.astype(np.float32)  / 255.0\n",
        "        mask = np.expand_dims(mask, axis=-1)\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "            mask = self.transform(mask)\n",
        "\n",
        "        return img, mask\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.ToTensor()\n",
        "dataset = SegmentationDataset(image_dir, mask_dir, transform=transform)"
      ],
      "metadata": {
        "id": "9u_yyatCmUNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8)\n",
        "\n",
        "# Instantiate the model, optimizer, and loss function\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UNet().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "PRn77o0tmcyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for images, masks in train_loader:\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, masks)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss / len(train_loader)}\")\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0\n",
        "        for images, masks in val_loader:\n",
        "            images = images.to(device)\n",
        "            masks = masks.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, masks)\n",
        "            val_loss += loss.item()\n",
        "\n",
        "        print(f\"Validation Loss: {val_loss / len(val_loader)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Sihb5prmhGx",
        "outputId": "1c08a176-3702-4ea9-cb41-0b59718fb838"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 0.6984755396842957\n",
            "Validation Loss: 0.6226633588473002\n",
            "Epoch [2/100], Loss: 0.48517543645132155\n",
            "Validation Loss: 0.4626832703749339\n",
            "Epoch [3/100], Loss: 0.4248088626634507\n",
            "Validation Loss: 0.45003903408845264\n",
            "Epoch [4/100], Loss: 0.40970335120246526\n",
            "Validation Loss: 0.4401915023724238\n",
            "Epoch [5/100], Loss: 0.38032856015931993\n",
            "Validation Loss: 0.37842748562494916\n",
            "Epoch [6/100], Loss: 0.32141913828395663\n",
            "Validation Loss: 0.33742887278397876\n",
            "Epoch [7/100], Loss: 0.29856324124903905\n",
            "Validation Loss: 0.36711379637320835\n",
            "Epoch [8/100], Loss: 0.29768483695529757\n",
            "Validation Loss: 0.31640640397866565\n",
            "Epoch [9/100], Loss: 0.28119711719808127\n",
            "Validation Loss: 0.3043758049607277\n",
            "Epoch [10/100], Loss: 0.2626284325406665\n",
            "Validation Loss: 0.2996428857247035\n",
            "Epoch [11/100], Loss: 0.2620268130586261\n",
            "Validation Loss: 0.2965271398425102\n",
            "Epoch [12/100], Loss: 0.2572320493913832\n",
            "Validation Loss: 0.31024697174628574\n",
            "Epoch [13/100], Loss: 0.26075042145592825\n",
            "Validation Loss: 0.32080110162496567\n",
            "Epoch [14/100], Loss: 0.25637350266888026\n",
            "Validation Loss: 0.29956428458293277\n",
            "Epoch [15/100], Loss: 0.24684231196131026\n",
            "Validation Loss: 0.3092699150244395\n",
            "Epoch [16/100], Loss: 0.2599049764020102\n",
            "Validation Loss: 0.28036532054344815\n",
            "Epoch [17/100], Loss: 0.25542069545813967\n",
            "Validation Loss: 0.2801467527945836\n",
            "Epoch [18/100], Loss: 0.24315354086103894\n",
            "Validation Loss: 0.2946659078200658\n",
            "Epoch [19/100], Loss: 0.23717942053363436\n",
            "Validation Loss: 0.271426518758138\n",
            "Epoch [20/100], Loss: 0.23746525673639207\n",
            "Validation Loss: 0.27064115554094315\n",
            "Epoch [21/100], Loss: 0.23051169301782334\n",
            "Validation Loss: 0.26831190784772235\n",
            "Epoch [22/100], Loss: 0.23556865113122122\n",
            "Validation Loss: 0.27039483437935513\n",
            "Epoch [23/100], Loss: 0.2303244790860585\n",
            "Validation Loss: 0.2500673135121663\n",
            "Epoch [24/100], Loss: 0.22665924898215703\n",
            "Validation Loss: 0.27607715129852295\n",
            "Epoch [25/100], Loss: 0.22991354621592022\n",
            "Validation Loss: 0.27584805836280185\n",
            "Epoch [26/100], Loss: 0.214077034166881\n",
            "Validation Loss: 0.2572425901889801\n",
            "Epoch [27/100], Loss: 0.20847061347393764\n",
            "Validation Loss: 0.25758560995260876\n",
            "Epoch [28/100], Loss: 0.2050048733750979\n",
            "Validation Loss: 0.23806567241748175\n",
            "Epoch [29/100], Loss: 0.1961245040098826\n",
            "Validation Loss: 0.2643383629620075\n",
            "Epoch [30/100], Loss: 0.19376922647158304\n",
            "Validation Loss: 0.24632392823696136\n",
            "Epoch [31/100], Loss: 0.18636485366594224\n",
            "Validation Loss: 0.2505875254670779\n",
            "Epoch [32/100], Loss: 0.1803016708720298\n",
            "Validation Loss: 0.23758396754662195\n",
            "Epoch [33/100], Loss: 0.17425826440254846\n",
            "Validation Loss: 0.31087841217716533\n",
            "Epoch [34/100], Loss: 0.19476452256952012\n",
            "Validation Loss: 0.30397462844848633\n",
            "Epoch [35/100], Loss: 0.1870546926345144\n",
            "Validation Loss: 0.2444015567501386\n",
            "Epoch [36/100], Loss: 0.1747163931528727\n",
            "Validation Loss: 0.23003811885913214\n",
            "Epoch [37/100], Loss: 0.17279744857833498\n",
            "Validation Loss: 0.23836463068922362\n",
            "Epoch [38/100], Loss: 0.16411920459497542\n",
            "Validation Loss: 0.23867774258057275\n",
            "Epoch [39/100], Loss: 0.15857531946329845\n",
            "Validation Loss: 0.22571063290039697\n",
            "Epoch [40/100], Loss: 0.15176269695872352\n",
            "Validation Loss: 0.2501356278856595\n",
            "Epoch [41/100], Loss: 0.14727075149615607\n",
            "Validation Loss: 0.2629013682405154\n",
            "Epoch [42/100], Loss: 0.14102766946667716\n",
            "Validation Loss: 0.24770653744538626\n",
            "Epoch [43/100], Loss: 0.14994699969178155\n",
            "Validation Loss: 0.24533669774731\n",
            "Epoch [44/100], Loss: 0.1424263854111944\n",
            "Validation Loss: 0.2634960686167081\n",
            "Epoch [45/100], Loss: 0.1716377997682208\n",
            "Validation Loss: 0.24876472353935242\n",
            "Epoch [46/100], Loss: 0.18035109305665606\n",
            "Validation Loss: 0.28401410828034085\n",
            "Epoch [47/100], Loss: 0.16066445906956991\n",
            "Validation Loss: 0.24846450984477997\n",
            "Epoch [48/100], Loss: 0.15127396157809667\n",
            "Validation Loss: 0.29158126438657445\n",
            "Epoch [49/100], Loss: 0.14472711902289165\n",
            "Validation Loss: 0.2521122160057227\n",
            "Epoch [50/100], Loss: 0.13416443055584318\n",
            "Validation Loss: 0.26476118465264636\n",
            "Epoch [51/100], Loss: 0.1419430509919212\n",
            "Validation Loss: 0.2554063101609548\n",
            "Epoch [52/100], Loss: 0.1396246822107406\n",
            "Validation Loss: 0.257075438896815\n",
            "Epoch [53/100], Loss: 0.12953983531111762\n",
            "Validation Loss: 0.25605185329914093\n",
            "Epoch [54/100], Loss: 0.11992328613996506\n",
            "Validation Loss: 0.27125022808710736\n",
            "Epoch [55/100], Loss: 0.11510627539384932\n",
            "Validation Loss: 0.2557336563865344\n",
            "Epoch [56/100], Loss: 0.11151299625635147\n",
            "Validation Loss: 0.2712118923664093\n",
            "Epoch [57/100], Loss: 0.10042164829515275\n",
            "Validation Loss: 0.2743016928434372\n",
            "Epoch [58/100], Loss: 0.0994906702211925\n",
            "Validation Loss: 0.26184939096371335\n",
            "Epoch [59/100], Loss: 0.10024535478580565\n",
            "Validation Loss: 0.2861679345369339\n",
            "Epoch [60/100], Loss: 0.09259753780705589\n",
            "Validation Loss: 0.2788916453719139\n",
            "Epoch [61/100], Loss: 0.09832318836734408\n",
            "Validation Loss: 0.32041119039058685\n",
            "Epoch [62/100], Loss: 0.089536556885356\n",
            "Validation Loss: 0.3106645718216896\n",
            "Epoch [63/100], Loss: 0.08064414259223711\n",
            "Validation Loss: 0.35919859011967975\n",
            "Epoch [64/100], Loss: 0.07789843990689233\n",
            "Validation Loss: 0.30603696405887604\n",
            "Epoch [65/100], Loss: 0.07371127782833009\n",
            "Validation Loss: 0.3761766900618871\n",
            "Epoch [66/100], Loss: 0.06884256413295156\n",
            "Validation Loss: 0.39212415119012195\n",
            "Epoch [67/100], Loss: 0.06499385851479712\n",
            "Validation Loss: 0.3699811299641927\n",
            "Epoch [68/100], Loss: 0.06007958558343705\n",
            "Validation Loss: 0.4255596747001012\n",
            "Epoch [69/100], Loss: 0.058297978448016305\n",
            "Validation Loss: 0.444173867503802\n",
            "Epoch [70/100], Loss: 0.0636558412086396\n",
            "Validation Loss: 0.4200286368529002\n",
            "Epoch [71/100], Loss: 0.06150107227620624\n",
            "Validation Loss: 0.44222312172253925\n",
            "Epoch [72/100], Loss: 0.054442664164872395\n",
            "Validation Loss: 0.480551153421402\n",
            "Epoch [73/100], Loss: 0.049006096309139616\n",
            "Validation Loss: 0.5422029693921407\n",
            "Epoch [74/100], Loss: 0.050735547074249814\n",
            "Validation Loss: 0.4711896280447642\n",
            "Epoch [75/100], Loss: 0.04658735827321098\n",
            "Validation Loss: 0.43560274442036945\n",
            "Epoch [76/100], Loss: 0.04303645786075365\n",
            "Validation Loss: 0.5378950834274292\n",
            "Epoch [77/100], Loss: 0.04449143340545041\n",
            "Validation Loss: 0.5497933874527613\n",
            "Epoch [78/100], Loss: 0.04423084251937412\n",
            "Validation Loss: 0.5547611117362976\n",
            "Epoch [79/100], Loss: 0.04164895326608703\n",
            "Validation Loss: 0.5416669944922129\n",
            "Epoch [80/100], Loss: 0.040810977951401754\n",
            "Validation Loss: 0.6086340298255285\n",
            "Epoch [81/100], Loss: 0.039944128621192204\n",
            "Validation Loss: 0.5773677676916122\n",
            "Epoch [82/100], Loss: 0.03651331764246736\n",
            "Validation Loss: 0.648590698838234\n",
            "Epoch [83/100], Loss: 0.035708739377913024\n",
            "Validation Loss: 0.5749932825565338\n",
            "Epoch [84/100], Loss: 0.03452906030274573\n",
            "Validation Loss: 0.6503087977568308\n",
            "Epoch [85/100], Loss: 0.03326328276168732\n",
            "Validation Loss: 0.6266293376684189\n",
            "Epoch [86/100], Loss: 0.03356639819131011\n",
            "Validation Loss: 0.6679281542698542\n",
            "Epoch [87/100], Loss: 0.03167689077201344\n",
            "Validation Loss: 0.6432594756285349\n",
            "Epoch [88/100], Loss: 0.03107024835688727\n",
            "Validation Loss: 0.7617171506086985\n",
            "Epoch [89/100], Loss: 0.029606505075380915\n",
            "Validation Loss: 0.7217714140812556\n",
            "Epoch [90/100], Loss: 0.029785911419561932\n",
            "Validation Loss: 0.6573531130949656\n",
            "Epoch [91/100], Loss: 0.03140153523002352\n",
            "Validation Loss: 0.6653533826271693\n",
            "Epoch [92/100], Loss: 0.03412098526245072\n",
            "Validation Loss: 0.5777447621027628\n",
            "Epoch [93/100], Loss: 0.032608895163450925\n",
            "Validation Loss: 0.691289484500885\n",
            "Epoch [94/100], Loss: 0.03109167773453962\n",
            "Validation Loss: 0.6175176898638407\n",
            "Epoch [95/100], Loss: 0.02950540388978663\n",
            "Validation Loss: 0.6785602023204168\n",
            "Epoch [96/100], Loss: 0.027870175650431997\n",
            "Validation Loss: 0.687548965215683\n",
            "Epoch [97/100], Loss: 0.028547709275569235\n",
            "Validation Loss: 0.7321985264619192\n",
            "Epoch [98/100], Loss: 0.026530032001790545\n",
            "Validation Loss: 0.6522749910751978\n",
            "Epoch [99/100], Loss: 0.024932102699364935\n",
            "Validation Loss: 0.7736529807249705\n",
            "Epoch [100/100], Loss: 0.02497751248024759\n",
            "Validation Loss: 0.8431034882863363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_continuous_metrics(y_true, y_pred, epsilon=1e-6):\n",
        "    # Flatten the arrays for metric calculation\n",
        "    y_true_flat = y_true.flatten()\n",
        "    y_pred_flat = y_pred.flatten()\n",
        "\n",
        "    # Intersection and Union for continuous IoU\n",
        "    intersection = np.sum(np.minimum(y_true_flat, y_pred_flat))\n",
        "    union = np.sum(np.maximum(y_true_flat, y_pred_flat))\n",
        "\n",
        "    iou = (intersection + epsilon) / (union + epsilon)  # Add epsilon to avoid division by zero\n",
        "\n",
        "    # Continuous F1 score (soft F1)\n",
        "    true_positives = np.sum(y_true_flat * y_pred_flat)\n",
        "    precision = true_positives / (np.sum(y_pred_flat) + epsilon)\n",
        "    recall = true_positives / (np.sum(y_true_flat) + epsilon)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall + epsilon)\n",
        "\n",
        "    return iou, f1\n"
      ],
      "metadata": {
        "id": "ZSw0AEkKmnlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "y_true = []\n",
        "y_pred = []\n",
        "with torch.no_grad():\n",
        "    for images, masks in val_loader:\n",
        "        images = images.to(device)\n",
        "        masks = masks.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        outputs = outputs.cpu().numpy()\n",
        "        masks = masks.cpu().numpy()\n",
        "\n",
        "        y_true.append(masks)\n",
        "        y_pred.append(outputs)\n",
        "\n",
        "# Concatenate all predictions and true masks\n",
        "y_true = np.concatenate(y_true, axis=0)\n",
        "y_pred = np.concatenate(y_pred, axis=0)\n",
        "\n",
        "# Apply a threshold to convert the continuous predictions to binary\n",
        "y_pred_thresholded = (y_pred > 0.5).astype(np.float32)\n",
        "\n",
        "# Now calculate IoU and F1 scores using the thresholded predictions\n",
        "iou, f1 = calculate_continuous_metrics(y_true, y_pred_thresholded)\n",
        "print(f\"IoU: {iou:.4f}, F1 Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoToKFvNoyWG",
        "outputId": "aa817ff3-2e97-460e-b169-067c77bb66dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IoU: 0.5891, F1 Score: 0.7414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir='/content/drive/MyDrive/busi_UNET_output'\n",
        "for idx in range(y_pred_thresholded.shape[0]):\n",
        "    pred_mask = y_pred_thresholded[idx, 0]  # Extract the predicted mask (single channel)\n",
        "    pred_mask = (pred_mask * 255).astype(np.uint8)  # Scale to 0-255\n",
        "\n",
        "    # Save the mask image\n",
        "    img_save_path = os.path.join(output_dir, f\"segmented_{idx}.png\")\n",
        "    cv2.imwrite(img_save_path, pred_mask)\n",
        "\n",
        "print(f\"Segmented images saved in {output_dir}\")"
      ],
      "metadata": {
        "id": "MyVsUKy2o16n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0b40751-eed8-4a58-cc75-223e267c7983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmented images saved in /content/drive/MyDrive/busi_UNET_output\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}